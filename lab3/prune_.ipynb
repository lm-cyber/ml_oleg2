{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-15T04:31:42.866999Z",
     "iopub.status.busy": "2024-12-15T04:31:42.866752Z",
     "iopub.status.idle": "2024-12-15T04:31:53.718720Z",
     "shell.execute_reply": "2024-12-15T04:31:53.717530Z",
     "shell.execute_reply.started": "2024-12-15T04:31:42.866973Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch-pruning ultralytics -q --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:31:53.721641Z",
     "iopub.status.busy": "2024-12-15T04:31:53.720853Z",
     "iopub.status.idle": "2024-12-15T04:31:54.705025Z",
     "shell.execute_reply": "2024-12-15T04:31:54.704224Z",
     "shell.execute_reply.started": "2024-12-15T04:31:53.721593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/last_last/pytorch/default/1/best.pt\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/last_last/pytorch/default/1/best.pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:33:53.829191Z",
     "iopub.status.busy": "2024-12-15T04:33:53.828392Z",
     "iopub.status.idle": "2024-12-15T04:33:54.895844Z",
     "shell.execute_reply": "2024-12-15T04:33:54.894886Z",
     "shell.execute_reply.started": "2024-12-15T04:33:53.829143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\tlabels\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/fishai-sample/annotations_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:32:17.704321Z",
     "iopub.status.busy": "2024-12-15T04:32:17.703985Z",
     "iopub.status.idle": "2024-12-15T04:32:22.714511Z",
     "shell.execute_reply": "2024-12-15T04:32:22.713772Z",
     "shell.execute_reply.started": "2024-12-15T04:32:17.704291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('/kaggle/input/last_last/pytorch/default/1/best.pt')\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:32:22.716307Z",
     "iopub.status.busy": "2024-12-15T04:32:22.715923Z",
     "iopub.status.idle": "2024-12-15T04:32:22.719994Z",
     "shell.execute_reply": "2024-12-15T04:32:22.719180Z",
     "shell.execute_reply.started": "2024-12-15T04:32:22.716279Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ignored_layers = []\n",
    "# for name, module in model.named_modules():\n",
    "#     if 'dfl' in name:\n",
    "#         ignored_layers.append(module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:32:22.721215Z",
     "iopub.status.busy": "2024-12-15T04:32:22.720970Z",
     "iopub.status.idle": "2024-12-15T04:32:22.734596Z",
     "shell.execute_reply": "2024-12-15T04:32:22.733709Z",
     "shell.execute_reply.started": "2024-12-15T04:32:22.721191Z"
    }
   },
   "outputs": [],
   "source": [
    "# indexs = [2, 4, 6, 8, 12, 15, 18, 21]\n",
    "\n",
    "# def get_model_groups(model, bottleneck_index):\n",
    "#         return [\n",
    "#             [\n",
    "#                 f\"model.{i}.m.{n}.cv2.conv\"\n",
    "#                 for n in range(len(model.module[i].m if hasattr(model, \"module\") else model[i].m))\n",
    "#             ]\n",
    "#             + [f\"model.{i}.cv1.conv\"]\n",
    "#             for i in bottleneck_index\n",
    "#         ]\n",
    "# groups = get_model_groups(model,indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:32:22.736395Z",
     "iopub.status.busy": "2024-12-15T04:32:22.736099Z",
     "iopub.status.idle": "2024-12-15T04:32:22.747108Z",
     "shell.execute_reply": "2024-12-15T04:32:22.746277Z",
     "shell.execute_reply.started": "2024-12-15T04:32:22.736371Z"
    }
   },
   "outputs": [],
   "source": [
    "# groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:32:22.748369Z",
     "iopub.status.busy": "2024-12-15T04:32:22.748124Z",
     "iopub.status.idle": "2024-12-15T04:32:22.760514Z",
     "shell.execute_reply": "2024-12-15T04:32:22.759722Z",
     "shell.execute_reply.started": "2024-12-15T04:32:22.748346Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from ultralytics.nn.modules import Detect, C2f, Conv, Bottleneck\n",
    "\n",
    "def infer_shortcut(bottleneck):\n",
    "    c1 = bottleneck.cv1.conv.in_channels\n",
    "    c2 = bottleneck.cv2.conv.out_channels\n",
    "    return c1 == c2 and hasattr(bottleneck, 'add') and bottleneck.add\n",
    "class C2f_v2(nn.Module):\n",
    "    # CSP Bottleneck with 2 convolutions\n",
    "    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n",
    "        super().__init__()\n",
    "        self.c = int(c2 * e)  # hidden channels\n",
    "        self.cv0 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv1 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)\n",
    "        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # y = list(self.cv1(x).chunk(2, 1))\n",
    "        y = [self.cv0(x), self.cv1(x)]\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        return self.cv2(torch.cat(y, 1))\n",
    "def replace_c2f_with_c2f_v2(module):\n",
    "    for name, child_module in module.named_children():\n",
    "        if isinstance(child_module, C2f):\n",
    "            # Replace C2f with C2f_v2 while preserving its parameters\n",
    "            shortcut = infer_shortcut(child_module.m[0])\n",
    "            c2f_v2 = C2f_v2(child_module.cv1.conv.in_channels, child_module.cv2.conv.out_channels,\n",
    "                            n=len(child_module.m), shortcut=shortcut,\n",
    "                            g=child_module.m[0].cv2.conv.groups,\n",
    "                            e=child_module.c / child_module.cv2.conv.out_channels)\n",
    "            transfer_weights(child_module, c2f_v2)\n",
    "            setattr(module, name, c2f_v2)\n",
    "        else:\n",
    "            replace_c2f_with_c2f_v2(child_module)\n",
    "\n",
    "def transfer_weights(c2f, c2f_v2):\n",
    "    c2f_v2.cv2 = c2f.cv2\n",
    "    c2f_v2.m = c2f.m\n",
    "\n",
    "    state_dict = c2f.state_dict()\n",
    "    state_dict_v2 = c2f_v2.state_dict()\n",
    "\n",
    "    # Transfer cv1 weights from C2f to cv0 and cv1 in C2f_v2\n",
    "    old_weight = state_dict['cv1.conv.weight']\n",
    "    half_channels = old_weight.shape[0] // 2\n",
    "    state_dict_v2['cv0.conv.weight'] = old_weight[:half_channels]\n",
    "    state_dict_v2['cv1.conv.weight'] = old_weight[half_channels:]\n",
    "\n",
    "    # Transfer cv1 batchnorm weights and buffers from C2f to cv0 and cv1 in C2f_v2\n",
    "    for bn_key in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "        old_bn = state_dict[f'cv1.bn.{bn_key}']\n",
    "        state_dict_v2[f'cv0.bn.{bn_key}'] = old_bn[:half_channels]\n",
    "        state_dict_v2[f'cv1.bn.{bn_key}'] = old_bn[half_channels:]\n",
    "\n",
    "    # Transfer remaining weights and buffers\n",
    "    for key in state_dict:\n",
    "        if not key.startswith('cv1.'):\n",
    "            state_dict_v2[key] = state_dict[key]\n",
    "\n",
    "    # Transfer all non-method attributes\n",
    "    for attr_name in dir(c2f):\n",
    "        attr_value = getattr(c2f, attr_name)\n",
    "        if not callable(attr_value) and '_' not in attr_name:\n",
    "            setattr(c2f_v2, attr_name, attr_value)\n",
    "\n",
    "    c2f_v2.load_state_dict(state_dict_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:32:22.762081Z",
     "iopub.status.busy": "2024-12-15T04:32:22.761761Z",
     "iopub.status.idle": "2024-12-15T04:32:32.851091Z",
     "shell.execute_reply": "2024-12-15T04:32:32.850242Z",
     "shell.execute_reply.started": "2024-12-15T04:32:22.762047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_pruning/pruner/algorithms/metapruner.py:91: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\"ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning: MACs=128.968017 G, #Params=0.068185 G\n",
      "After Pruning: MACs=18.232305 G, #Params=0.008156 G\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch_pruning as tp\n",
    "\n",
    "from ultralytics.nn.modules import Detect\n",
    "\n",
    "\n",
    "def prune(model):\n",
    "\n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    replace_c2f_with_c2f_v2(model.model)\n",
    "    model.model.eval()\n",
    "    example_inputs = torch.randn(1, 3, 640, 640).to(model.device)\n",
    "    imp = tp.importance.MagnitudeImportance(p=2)  \n",
    "\n",
    "    ignored_layers = []\n",
    "    unwrapped_parameters = []\n",
    "\n",
    "    modules_list = list(model.model.modules())\n",
    "    for i, m in enumerate(modules_list):\n",
    "        if isinstance(m, (Detect,)):\n",
    "            ignored_layers.append(m)\n",
    "\n",
    "    iterative_steps =1 \n",
    "    pruner = tp.pruner.MagnitudePruner(\n",
    "        model.model,\n",
    "        example_inputs,\n",
    "        importance=imp,\n",
    "        iterative_steps=iterative_steps,\n",
    "        ch_sparsity=0.75,  \n",
    "        ignored_layers=ignored_layers,\n",
    "        unwrapped_parameters=unwrapped_parameters\n",
    "    )\n",
    "    base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs)\n",
    "    pruner.step()\n",
    "\n",
    "    pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(pruner.model, example_inputs)\n",
    "    # print(model.model)\n",
    "    print(\"Before Pruning: MACs=%f G, #Params=%f G\" % (base_macs / 1e9, base_nparams / 1e9))\n",
    "    print(\"After Pruning: MACs=%f G, #Params=%f G\" % (pruned_macs / 1e9, pruned_nparams / 1e9))\n",
    "prune(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:33:38.340337Z",
     "iopub.status.busy": "2024-12-15T04:33:38.339970Z",
     "iopub.status.idle": "2024-12-15T04:33:38.369697Z",
     "shell.execute_reply": "2024-12-15T04:33:38.368809Z",
     "shell.execute_reply.started": "2024-12-15T04:33:38.340306Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(torch.rand(1,3,640,640),verbose=False)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:34:00.735784Z",
     "iopub.status.busy": "2024-12-15T04:34:00.735392Z",
     "iopub.status.idle": "2024-12-15T04:34:01.794118Z",
     "shell.execute_reply": "2024-12-15T04:34:01.793053Z",
     "shell.execute_reply.started": "2024-12-15T04:34:00.735750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\tlabels\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/fishai-sample/annotations_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:34:28.067606Z",
     "iopub.status.busy": "2024-12-15T04:34:28.066723Z",
     "iopub.status.idle": "2024-12-15T04:34:28.073393Z",
     "shell.execute_reply": "2024-12-15T04:34:28.072331Z",
     "shell.execute_reply.started": "2024-12-15T04:34:28.067553Z"
    }
   },
   "outputs": [],
   "source": [
    "str_data = \"\"\"\n",
    "train: /kaggle/input/fishai-sample/annotations_s/images/train  # Path to training images\n",
    "val: /kaggle/input/fishai-sample/annotations_s/images/val      # Path to validation images\n",
    "\n",
    "labels:\n",
    "  train: /kaggle/input/fishai-sample/annotations_s/labels/train  # Path to training labels\n",
    "  val: /kaggle/input/fishai-sample/annotations_s/labels/val      # Path to validation labels\n",
    "\n",
    "\n",
    "names:\n",
    "  0: Long snouted lancetfish\n",
    "  1: Roudie scolar\n",
    "  2: Marlin\n",
    "  3: Swordfish\n",
    "  4: Great barracuda\n",
    "  5: Thresher shark\n",
    "  6: Lancetfish\n",
    "  7: Pomfret\n",
    "  8: Tuna\n",
    "  9: Opah\n",
    "  10: Pelagic stingray\n",
    "  11: Mahi mahi\n",
    "  12: Striped marlin\n",
    "  13: Wahoo\n",
    "  14: No fish\n",
    "  15: Human\n",
    "  16: Skipjack tuna\n",
    "  17: Yellowfin tuna\n",
    "  18: Unknown\n",
    "  19: Blue marlin\n",
    "  20: Oilfish\n",
    "  21: Bigeye tuna\n",
    "  22: Snake mackerel\n",
    "  23: Indo Pacific sailfish\n",
    "  24: Water\n",
    "  25: Sickle pomfret\n",
    "  26: Albacore\n",
    "  27: Brama\n",
    "  28: Black marlin\n",
    "  29: Shortbill spearfish\n",
    "  30: Mola mola\n",
    "  31: Rainbow runner\n",
    "  32: Escolar\n",
    "  33: Shark\n",
    "\"\"\"\n",
    "with open('test.yaml','w') as f:\n",
    "    f.write(str_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:34:59.654113Z",
     "iopub.status.busy": "2024-12-15T04:34:59.653753Z",
     "iopub.status.idle": "2024-12-15T04:38:14.097893Z",
     "shell.execute_reply": "2024-12-15T04:38:14.096972Z",
     "shell.execute_reply.started": "2024-12-15T04:34:59.654084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/last_last/pytorch/default/1/best.pt, data=test.yaml, epochs=1, time=None, patience=100, batch=0.95, imgsz=640, save=True, save_period=-1, cache=False, device=[0], workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 21.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8750710  ultralytics.nn.modules.head.Detect           [34, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68,185,350 parameters, 68,185,334 gradients, 258.3 GFLOPs\n",
      "\n",
      "Transferred 19/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 105MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/fishai-sample/annotations_s/labels/train... 1000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1000/1000 [00:03<00:00, 278.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3973f8-5952-11ec-b44b-af65662ddbd4.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3dc4d0-5952-11ec-bd4e-e7aff7c46c27.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3e87b2-5952-11ec-becf-9fbe13c9d4bb.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3fa4bc-5952-11ec-853f-ff86f68c9e15.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4010f0-5952-11ec-8628-8f458d687932.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4068ac-5952-11ec-86f1-771ed3bdde36.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc40914c-5952-11ec-8740-c727babca0ed.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc422c14-5952-11ec-8aad-1fc4b59d67cc.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc424280-5952-11ec-8ae7-3fd5820faafd.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4259be-5952-11ec-8b0b-abc20039966d.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc426f6c-5952-11ec-8b29-2f6e8b2b2c4e.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc45001a-5952-11ec-8f8f-331180ee8143.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc451938-5952-11ec-8fb0-e39cfe73431b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4775c0-5952-11ec-9268-a78876d4492e.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc488b9a-5952-11ec-93ad-43f0d1d68df8.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4b076c-5952-11ec-9612-03736cc672bd.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4b1f9a-5952-11ec-9644-9fe1eff954a4.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc8de0be-5952-11ec-b3ed-0fa3ae6d8456.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc979c30-5952-11ec-be67-cfe3df88d94b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc981084-5952-11ec-beec-4fd9eff5ee75.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9884ec-5952-11ec-bf87-b37030e50e44.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc993b4e-5952-11ec-b61a-5f9141241cce.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc996a7e-5952-11ec-b646-2bc296b6f9fe.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc998b6c-5952-11ec-b678-17b7e6e5b4ab.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9af150-5952-11ec-b833-2f06f64b84b4.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9ccb24-5952-11ec-ba87-0b978b645d25.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9d1b92-5952-11ec-baf9-2f11f00defb5.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9d3f3c-5952-11ec-bb1c-8fe05d1862f1.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9e9c56-5952-11ec-bcb5-337caad8673f.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fca6b9cc-5952-11ec-bee5-d34e00198aa4.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fca97838-5952-11ec-97f4-7b2867169048.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcabc160-5952-11ec-9ab8-7f96f16aaf23.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcaccb5a-5952-11ec-9be9-2bd7b8eb633c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcadc316-5952-11ec-9d19-33ca7d82e1c1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcae713a-5952-11ec-9ded-2b85359d65d1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcafb374-5952-11ec-9f99-a7e2fa31a693.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcb21f1a-5952-11ec-a2a2-af3f8fa61292.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcb24a6c-5952-11ec-a2cf-f752397f1138.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcb510d0-5952-11ec-a657-fb6bf2aa6d0b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcba1a08-5952-11ec-acb3-d35d76f76b8a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcbee966-5952-11ec-b2c6-3fe39d0ef97d.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcbfc57a-5952-11ec-b3e9-cf949d18a197.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcc887c8-5952-11ec-b709-af70b78c00f6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcc8fe60-5952-11ec-b788-578f0301df1e.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd29d08-5952-11ec-bb1a-47235c3d8194.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd2aaf0-5952-11ec-bb32-f3204733c23e.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd48442-5952-11ec-bd31-abed02b599b6.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd5a8b8-5952-11ec-bdf8-c7f2d6d3f604.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd721e8-5952-11ec-bed5-1b56b39ba054.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd8ad1a-5952-11ec-a1a7-abf5a9e2bb54.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd8ade2-5952-11ec-a1a9-ef6aeef95c8d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd98276-5952-11ec-a285-1b5a41bf268a.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcda23c0-5952-11ec-a340-e3896104db7b.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcdca172-5952-11ec-a601-5789f53f735f.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce0b49c-5952-11ec-aab5-b7aa7b76526d.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce16ea0-5952-11ec-ab82-77b3fc65cde4.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce46c86-5952-11ec-aed0-3b1db290d4f7.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce63b24-5952-11ec-b036-df59903e86f9.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce64024-5952-11ec-b041-e3c2bf81c9e6.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce7e76c-5952-11ec-b21c-fbf2e89ce7b6.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcebb676-5952-11ec-b6c3-6b7de4966346.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcecb10c-5952-11ec-b7f9-f7813a669809.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fced94a0-5952-11ec-b908-1fbdc18ded47.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fceef264-5952-11ec-ba94-b7be1beb0434.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcf9934a-5952-11ec-bf68-2b47d0e3e590.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcfba98c-5952-11ec-9e36-bbe5df0dff85.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcfde364-5952-11ec-a0ef-036a5d795515.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcfe3a62-5952-11ec-a151-87ba034bb18a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcffcf6c-5952-11ec-a36e-9b3916c7cef8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd00d7a4-5952-11ec-a4b2-b3d5a31ae339.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd03c57c-5952-11ec-a836-b32383adeb8d.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd03e188-5952-11ec-a85b-9ba7d0a85f19.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd053254-5952-11ec-a9de-d775f222a592.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd0d2a7c-5952-11ec-ab8d-6b23b042bc64.jpg: 3 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/fishai-sample/annotations_s/labels is not writeable, cache not saved.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 95.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.62G reserved, 0.59G allocated, 14.68G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    68185350       258.3         1.497         66.68         156.1        (1, 3, 640, 640)                    list\n",
      "    68185350       516.6         2.147         74.49         113.2        (2, 3, 640, 640)                    list\n",
      "    68185350        1033         3.825         132.2         176.4        (4, 3, 640, 640)                    list\n",
      "    68185350        2066         6.564         251.5         305.9        (8, 3, 640, 640)                    list\n",
      "    68185350        4133        12.721         402.1         541.9       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 17 for CUDA:0 14.64G/15.89G (92%) ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/fishai-sample/annotations_s/labels/train... 1000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1000/1000 [00:01<00:00, 778.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3973f8-5952-11ec-b44b-af65662ddbd4.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3dc4d0-5952-11ec-bd4e-e7aff7c46c27.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3e87b2-5952-11ec-becf-9fbe13c9d4bb.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc3fa4bc-5952-11ec-853f-ff86f68c9e15.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4010f0-5952-11ec-8628-8f458d687932.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4068ac-5952-11ec-86f1-771ed3bdde36.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc40914c-5952-11ec-8740-c727babca0ed.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc422c14-5952-11ec-8aad-1fc4b59d67cc.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc424280-5952-11ec-8ae7-3fd5820faafd.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4259be-5952-11ec-8b0b-abc20039966d.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc426f6c-5952-11ec-8b29-2f6e8b2b2c4e.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc45001a-5952-11ec-8f8f-331180ee8143.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc451938-5952-11ec-8fb0-e39cfe73431b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4775c0-5952-11ec-9268-a78876d4492e.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc488b9a-5952-11ec-93ad-43f0d1d68df8.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4b076c-5952-11ec-9612-03736cc672bd.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc4b1f9a-5952-11ec-9644-9fe1eff954a4.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc8de0be-5952-11ec-b3ed-0fa3ae6d8456.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc979c30-5952-11ec-be67-cfe3df88d94b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc981084-5952-11ec-beec-4fd9eff5ee75.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9884ec-5952-11ec-bf87-b37030e50e44.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc993b4e-5952-11ec-b61a-5f9141241cce.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc996a7e-5952-11ec-b646-2bc296b6f9fe.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc998b6c-5952-11ec-b678-17b7e6e5b4ab.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9af150-5952-11ec-b833-2f06f64b84b4.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9ccb24-5952-11ec-ba87-0b978b645d25.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9d1b92-5952-11ec-baf9-2f11f00defb5.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9d3f3c-5952-11ec-bb1c-8fe05d1862f1.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fc9e9c56-5952-11ec-bcb5-337caad8673f.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fca6b9cc-5952-11ec-bee5-d34e00198aa4.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fca97838-5952-11ec-97f4-7b2867169048.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcabc160-5952-11ec-9ab8-7f96f16aaf23.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcaccb5a-5952-11ec-9be9-2bd7b8eb633c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcadc316-5952-11ec-9d19-33ca7d82e1c1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcae713a-5952-11ec-9ded-2b85359d65d1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcafb374-5952-11ec-9f99-a7e2fa31a693.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcb21f1a-5952-11ec-a2a2-af3f8fa61292.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcb24a6c-5952-11ec-a2cf-f752397f1138.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcb510d0-5952-11ec-a657-fb6bf2aa6d0b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcba1a08-5952-11ec-acb3-d35d76f76b8a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcbee966-5952-11ec-b2c6-3fe39d0ef97d.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcbfc57a-5952-11ec-b3e9-cf949d18a197.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcc887c8-5952-11ec-b709-af70b78c00f6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcc8fe60-5952-11ec-b788-578f0301df1e.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd29d08-5952-11ec-bb1a-47235c3d8194.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd2aaf0-5952-11ec-bb32-f3204733c23e.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd48442-5952-11ec-bd31-abed02b599b6.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd5a8b8-5952-11ec-bdf8-c7f2d6d3f604.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd721e8-5952-11ec-bed5-1b56b39ba054.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd8ad1a-5952-11ec-a1a7-abf5a9e2bb54.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd8ade2-5952-11ec-a1a9-ef6aeef95c8d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcd98276-5952-11ec-a285-1b5a41bf268a.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcda23c0-5952-11ec-a340-e3896104db7b.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcdca172-5952-11ec-a601-5789f53f735f.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce0b49c-5952-11ec-aab5-b7aa7b76526d.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce16ea0-5952-11ec-ab82-77b3fc65cde4.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce46c86-5952-11ec-aed0-3b1db290d4f7.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce63b24-5952-11ec-b036-df59903e86f9.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce64024-5952-11ec-b041-e3c2bf81c9e6.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fce7e76c-5952-11ec-b21c-fbf2e89ce7b6.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcebb676-5952-11ec-b6c3-6b7de4966346.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcecb10c-5952-11ec-b7f9-f7813a669809.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fced94a0-5952-11ec-b908-1fbdc18ded47.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fceef264-5952-11ec-ba94-b7be1beb0434.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcf9934a-5952-11ec-bf68-2b47d0e3e590.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcfba98c-5952-11ec-9e36-bbe5df0dff85.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcfde364-5952-11ec-a0ef-036a5d795515.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcfe3a62-5952-11ec-a151-87ba034bb18a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fcffcf6c-5952-11ec-a36e-9b3916c7cef8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd00d7a4-5952-11ec-a4b2-b3d5a31ae339.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd03c57c-5952-11ec-a836-b32383adeb8d.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd03e188-5952-11ec-a85b-9ba7d0a85f19.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd053254-5952-11ec-a9de-d775f222a592.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/train/fd0d2a7c-5952-11ec-ab8d-6b23b042bc64.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/fishai-sample/annotations_s/labels is not writeable, cache not saved.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/fishai-sample/annotations_s/labels/val... 1000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1000/1000 [00:03<00:00, 259.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3d8074-5952-11ec-bcc6-37871c7a8a7a.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3d8452-5952-11ec-bcd0-8bf539563886.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3e1b10-5952-11ec-bdd5-37b5fe4f6797.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3ec862-5952-11ec-bf66-0b4446dff47b.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3f087c-5952-11ec-83f2-ffc3ab520574.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3f82de-5952-11ec-84f2-b744f9e169f5.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3fce74-5952-11ec-85af-63757a9c6273.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc3fd5a4-5952-11ec-85c1-330b5a449143.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc4146c8-5952-11ec-88cd-6f4219d3712d.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc41a17c-5952-11ec-89a2-4f092e684db1.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc440f20-5952-11ec-8edd-631013890f9a.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc480c74-5952-11ec-930d-07f6d9c61b62.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc485b20-5952-11ec-9369-3b3fbac4e1e5.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc4b1c5c-5952-11ec-963c-bfe102ba281b.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc4b73dc-5952-11ec-96f8-df1ac2cc70b8.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc8de2d0-5952-11ec-b3f2-0f502748fe21.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fc9bb89c-5952-11ec-b92f-9b961390ccb3.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fca7ceb6-5952-11ec-9608-1757e5d48382.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fca87424-5952-11ec-96d2-471bf60272df.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcab0220-5952-11ec-99cd-6bac25b4cafa.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcaf34e4-5952-11ec-9ee8-d788170118e2.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcb05b6c-5952-11ec-a061-0b95ca180bf5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcb1153e-5952-11ec-a145-dffc36590c32.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcb1b232-5952-11ec-a213-4754e0c1c7b8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcb2e22e-5952-11ec-a38e-1fd0321554c7.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcb57b10-5952-11ec-a6d7-0744fbe774e9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcb8934a-5952-11ec-aaa9-9b00fdc872b1.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcbe5f5a-5952-11ec-b21f-7751dbba0d77.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcbe60cc-5952-11ec-b223-d7f3ce07ec3f.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcbeb9aa-5952-11ec-b282-2ba81cb28dc7.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcbecdfa-5952-11ec-b29c-4748d03ccb80.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcc06480-5952-11ec-b4b6-87017f46bf30.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcc0676e-5952-11ec-b4be-2f9b5654be4b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcc09e14-5952-11ec-b503-274928b69f33.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcc0d5c8-5952-11ec-b553-a7298af5aae1.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcc81aae-5952-11ec-b6ca-2736f66f012c.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcd3561c-5952-11ec-bbdf-a33fd5778257.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcd3a162-5952-11ec-bc43-3b59c428182b.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcd3baee-5952-11ec-bc5f-ef4d58924c1f.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcd66fdc-5952-11ec-be1c-2392ce5f5cf8.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcdba100-5952-11ec-a4dd-77c00c74ca1a.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fce11cb6-5952-11ec-ab2b-5f1226f387ee.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fce1be3c-5952-11ec-abe9-fb2e912e3388.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fce9dd1a-5952-11ec-b474-73775d06350a.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fceb24b8-5952-11ec-b602-6f5b67cf4c62.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcf6ee92-5952-11ec-bc48-4b596a263ad1.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcfa074e-5952-11ec-bff3-232e6367e552.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcfb5266-5952-11ec-9ddf-977adcc9c55b.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcfc9810-5952-11ec-9f5e-ff3e60443e58.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcfdb3bc-5952-11ec-a0bc-e30032143254.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fcffceae-5952-11ec-a36c-0b27a47d45c5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fd0084de-5952-11ec-a449-1332312a27b5.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fd00ba44-5952-11ec-a484-a3f4f2b8785d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fd021ccc-5952-11ec-a62f-0fd631190337.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fd02715e-5952-11ec-a6ab-93105f892bf2.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/fishai-sample/annotations_s/images/val/fd0412f2-5952-11ec-a892-c3d07094db01.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/fishai-sample/annotations_s/labels is not writeable, cache not saved.\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000263, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00053125), 103 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      14.3G      3.654      5.158      3.389         75        640: 100%|██████████| 59/59 [01:38<00:00,  1.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:19<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       3516          0.612      0.332      0.367       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 136.8MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 136.8MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.49 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "Model summary (fused): 268 layers, 68,156,310 parameters, 0 gradients, 257.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:19<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       3516         0.592      0.343      0.308      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.1ms preprocess, 17.8ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=\"test.yaml\", epochs=1, imgsz=640,device=[0],batch=0.95,augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:39:03.604063Z",
     "iopub.status.busy": "2024-12-15T04:39:03.603188Z",
     "iopub.status.idle": "2024-12-15T04:39:04.130906Z",
     "shell.execute_reply": "2024-12-15T04:39:04.129949Z",
     "shell.execute_reply.started": "2024-12-15T04:39:03.604027Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('result.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T04:39:27.773132Z",
     "iopub.status.busy": "2024-12-15T04:39:27.772787Z",
     "iopub.status.idle": "2024-12-15T04:39:27.779744Z",
     "shell.execute_reply": "2024-12-15T04:39:27.778744Z",
     "shell.execute_reply.started": "2024-12-15T04:39:27.773103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='result.pt' target='_blank'>result.pt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/result.pt"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('result.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6259625,
     "sourceId": 10141680,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 186820,
     "modelInstanceId": 164489,
     "sourceId": 192883,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
